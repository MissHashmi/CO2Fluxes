{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b96ccd",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "## Step 1: Data extraction using Google Earth Engine (GEE)\n",
    "\n",
    "The data extraction is performed using a script written in Google Earth Engine.\n",
    "\n",
    "1. Open the following link in a web browser:  \n",
    "   https://code.earthengine.google.com/c2a490d827f13217b3cc88ca2c7a0b3b\n",
    "\n",
    "2. Click Run to execute the script.\n",
    "\n",
    "3. After execution, open the Tasks tab.\n",
    "\n",
    "4. Start the export task and download the generated CSV file to your local machine.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Python analysis in Jupyter Notebook / VS Code\n",
    "\n",
    "The downloaded CSV file is used as input for the Python-based analysis.\n",
    "\n",
    "### Install required dependencies\n",
    "\n",
    "Install the required Python libraries based on the imports used in the notebook:\n",
    "\n",
    "\n",
    "pip install pandas numpy matplotlib scikit-learn\n",
    "\n",
    "## Step 3: Run the code\n",
    "\n",
    "Now the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70977afb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325c04f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EVI_season_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rr151\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'EVI_season_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     18\u001b[39m numeric_cols = [\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEVI_season_mean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNDVI_season_mean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mseason_end_month\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     df[c] = pd.to_numeric(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Drop rows with missing key values\u001b[39;00m\n\u001b[32m     34\u001b[39m df = df.dropna(subset=[\n\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEVI_season_mean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNDVI_season_mean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrop_key\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rr151\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rr151\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'EVI_season_mean'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    " \n",
    "# =========================\n",
    "# 1) Load the CSV\n",
    "# =========================\n",
    "# Update filename if needed\n",
    "df = pd.read_csv(r\"C:\\Users\\numra\\Downloads\\python\\co2.ipynb\")\n",
    " \n",
    "# Quick cleanup: make sure numeric cols are numeric\n",
    "numeric_cols = [\n",
    "    \"EVI_season_mean\",\n",
    "    \"NDVI_season_mean\",\n",
    "    \"GPP_season_tCO2_ha\",\n",
    "    \"Reco_season_tCO2_ha\",\n",
    "    \"NEE_season_tCO2_ha\",\n",
    "    \"months_with_S2\",\n",
    "    \"year\",\n",
    "    \"season_start_month\",\n",
    "    \"season_end_month\"\n",
    "]\n",
    " \n",
    "for c in numeric_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    " \n",
    "# Drop rows with missing key values\n",
    "df = df.dropna(subset=[\n",
    "    \"EVI_season_mean\",\n",
    "    \"NDVI_season_mean\",\n",
    "    \"GPP_season_tCO2_ha\",\n",
    "    \"Reco_season_tCO2_ha\",\n",
    "    \"year\",\n",
    "    \"crop_key\"\n",
    "])\n",
    " \n",
    "# =========================\n",
    "# 2) Feature engineering\n",
    "# =========================\n",
    "# Season length and mid month (phenology differences)\n",
    "df[\"season_length\"] = df[\"season_end_month\"] - df[\"season_start_month\"] + 1\n",
    "df[\"season_mid_month\"] = (df[\"season_start_month\"] + df[\"season_end_month\"]) / 2.0\n",
    " \n",
    "# NDVI-EVI gap\n",
    "df[\"ndvi_minus_evi\"] = df[\"NDVI_season_mean\"] - df[\"EVI_season_mean\"]\n",
    " \n",
    "feature_cols = [\n",
    "    \"EVI_season_mean\",\n",
    "    \"NDVI_season_mean\",\n",
    "    \"ndvi_minus_evi\",\n",
    "    \"months_with_S2\",\n",
    "    \"year\",\n",
    "    \"season_length\",\n",
    "    \"season_mid_month\",\n",
    "    \"crop_key\"\n",
    "]\n",
    " \n",
    "X = df[feature_cols].copy()\n",
    " \n",
    "# Targets\n",
    "y_gpp = df[\"GPP_season_tCO2_ha\"].copy()\n",
    "y_reco = df[\"Reco_season_tCO2_ha\"].copy()\n",
    " \n",
    "# =========================\n",
    "# 3) Preprocessing pipeline\n",
    "# =========================\n",
    "categorical_features = [\"crop_key\"]\n",
    "numeric_features = [c for c in feature_cols if c not in categorical_features]\n",
    " \n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Ridge regression models\n",
    "gpp_model = Pipeline(steps=[(\"prep\", preprocess), (\"model\", Ridge(alpha=1.0))])\n",
    "reco_model = Pipeline(steps=[(\"prep\", preprocess), (\"model\", Ridge(alpha=1.0))])\n",
    " \n",
    "# =========================\n",
    "# 4) Validation: LOOCV\n",
    "# =========================\n",
    "loo = LeaveOneOut()\n",
    "gpp_pred = cross_val_predict(gpp_model, X, y_gpp, cv=loo)\n",
    "reco_pred = cross_val_predict(reco_model, X, y_reco, cv=loo)\n",
    " \n",
    "# Metrics function\n",
    "def metrics(y_true, y_hat):\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_hat)))\n",
    "    mae = float(mean_absolute_error(y_true, y_hat))\n",
    "    r2 = float(r2_score(y_true, y_hat))\n",
    "    bias = float(np.mean(y_hat - y_true))\n",
    "    return rmse, mae, r2, bias\n",
    " \n",
    "rmse_gpp, mae_gpp, r2_gpp, bias_gpp = metrics(y_gpp, gpp_pred)\n",
    "rmse_reco, mae_reco, r2_reco, bias_reco = metrics(y_reco, reco_pred)\n",
    " \n",
    "print(\"=== LOOCV Performance ===\")\n",
    "print(f\"GPP -> RMSE={rmse_gpp:.3f}, MAE={mae_gpp:.3f}, R2={r2_gpp:.3f}, Bias={bias_gpp:.3f}\")\n",
    "print(f\"Reco -> RMSE={rmse_reco:.3f}, MAE={mae_reco:.3f}, R2={r2_reco:.3f}, Bias={bias_reco:.3f}\")\n",
    " \n",
    "# =========================\n",
    "# 5) Compute NEE from predictions + compare\n",
    "# =========================\n",
    "nee_true = df[\"NEE_season_tCO2_ha\"].values\n",
    "nee_pred = gpp_pred - reco_pred  # consistent with your model definition\n",
    " \n",
    "rmse_nee, mae_nee, r2_nee, bias_nee = metrics(nee_true, nee_pred)\n",
    "print(f\"NEE(pred=GPP_pred-Reco_pred) -> RMSE={rmse_nee:.3f}, MAE={mae_nee:.3f}, R2={r2_nee:.3f}, Bias={bias_nee:.3f}\")\n",
    " \n",
    "# =========================\n",
    "# 6) Plot NEE by crop over time (Observed & Predicted)\n",
    "# =========================\n",
    "plot_df = df[[\"crop_key\",\"crop_name\",\"year\",\"NEE_season_tCO2_ha\"]].copy()\n",
    "plot_df[\"NEE_pred\"] = nee_pred\n",
    "plot_df = plot_df.sort_values([\"crop_key\",\"year\"])\n",
    " \n",
    "# Observed NEE\n",
    "plt.figure()\n",
    "for crop in plot_df[\"crop_key\"].unique():\n",
    "    sub = plot_df[plot_df[\"crop_key\"] == crop]\n",
    "    plt.plot(sub[\"year\"], sub[\"NEE_season_tCO2_ha\"], marker=\"o\", label=f\"{crop} (obs)\")\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"NEE (tCO2/ha/season)\")\n",
    "plt.title(\"Seasonal Net CO2 (NEE) by crop — Observed\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "# Predicted NEE\n",
    "plt.figure()\n",
    "for crop in plot_df[\"crop_key\"].unique():\n",
    "    sub = plot_df[plot_df[\"crop_key\"] == crop]\n",
    "    plt.plot(sub[\"year\"], sub[\"NEE_pred\"], marker=\"o\", label=f\"{crop} (pred)\")\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"NEE (tCO2/ha/season)\")\n",
    "plt.title(\"Seasonal Net CO2 (NEE) by crop — Predicted from ML GPP & Reco\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "# =========================\n",
    "# 7) Crop contribution summary\n",
    "# =========================\n",
    "summary = plot_df.groupby([\"crop_key\",\"crop_name\"])[\"NEE_season_tCO2_ha\"].agg(\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    std=\"std\",\n",
    "    min=\"min\",\n",
    "    max=\"max\",\n",
    "    total=\"sum\"\n",
    ").reset_index()\n",
    " \n",
    "print(\"\\n=== Crop NEE summary (observed) ===\")\n",
    "print(summary.sort_values(\"mean\"))\n",
    " \n",
    "# Ranking for strongest sink (most uptake)\n",
    "print(\"\\nRanking (strongest sink / most uptake):\")\n",
    "print(summary.sort_values(\"mean\", ascending=False)[[\"crop_key\",\"crop_name\",\"mean\",\"total\"]])\n",
    " \n",
    "# Ranking for strongest source (most release)\n",
    "print(\"\\nRanking (strongest source / most release):\")\n",
    "print(summary.sort_values(\"mean\", ascending=True)[[\"crop_key\",\"crop_name\",\"mean\",\"total\"]])\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
